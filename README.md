# Airflow ETL Pipeline

![Airflow Version](https://img.shields.io/badge/Airflow-2.7.2-blue)
![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue)

Pipeline ETL profesional para procesamiento de datos con:

- ExtracciÃ³n desde S3
- TransformaciÃ³n con Pandas
- Carga a PostgreSQL
- ValidaciÃ³n de datos
- Monitoreo integrado

ğŸ› ï¸ Features
Modern Data Stack

Airflow 2.0 TaskFlow API

XCom backend with S3

Python 3.10 type hints

Data Quality

Column-level checks

Statistical validation

Automated reporting (Markdown + S3)

DevOps Ready

Dockerized environment

Kubernetes-ready configuration

Automated testing framework

Security

Fernet key encryption

Secrets management with .env

RBAC-ready configuration


## ğŸš€ InstalaciÃ³n

1. Clonar repositorio
2. Configurar `.env` basado en `env.example`
3. Ejecutar:


## ğŸ“‚ Project Structure

```bash
airflow-project/
â”œâ”€â”€ dags/                   # Pipeline definitions
â”‚   â”œâ”€â”€ etl_s3_to_postgres.py    # Main ETL workflow
â”‚   â”œâ”€â”€ data_validation_dag.py   # Data quality checks
â”‚   â”œâ”€â”€ api_etl_dag.py           # API ingestion pipeline
â”‚   â””â”€â”€ ...
â”œâ”€â”€ config/                # Environment configuration
â”œâ”€â”€ docker/                # Docker infrastructure
â”œâ”€â”€ tests/                 # Unit and integration tests
â”œâ”€â”€ scripts/               # Automation scripts
â”œâ”€â”€ .gitignore            # Version control config
â”œâ”€â”€ docker-compose.yml     # Local orchestration
â”œâ”€â”€ Makefile               # Build automation
â””â”€â”€ README.md              # Project documentation
